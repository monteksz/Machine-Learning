{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "pwNbhixa79zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIAOvVJ2Bwrh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SelectKBest, f_regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ganti \"path/to/your/file\" dengan path yang benar dari file Anda\n",
        "file_path = '/content/drive/MyDrive/Dataset/RegresiUTSTelkom.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "JrJvpTAzofoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti nama kolom agar lebih mudah dipanggil\n",
        "data.columns = [f\"col_{i}\" for i in range(data.shape[1])]\n",
        "\n",
        "# Memeriksa informasi dataset setelah mengganti nama kolom\n",
        "data.info()\n",
        "\n",
        "# Menangani missing values (jika ada)\n",
        "data = data.dropna()  # atau gunakan fillna sesuai kebutuhan\n",
        "\n",
        "# Normalisasi kolom-kolom numerik menggunakan MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data[data.columns] = scaler.fit_transform(data[data.columns])\n",
        "\n",
        "# Menampilkan 5 data pertama setelah preprocessing\n",
        "data.head()"
      ],
      "metadata": {
        "id": "OtzHxThs1ReB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ringkasan statistik dasar\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "-MMui1dd2FB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi distribusi untuk kolom-kolom awal\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Distribusi Kolom Utama')\n",
        "\n",
        "for i, col in enumerate(data.columns[:6]):\n",
        "    sns.histplot(data[col], bins=30, kde=True, ax=axes[i//3, i%3])\n",
        "    axes[i//3, i%3].set_title(f'Distribusi {col}')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PDHfE6tP2GYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi heatmap untuk subset kolom\n",
        "subset_corr = data[data.columns[:23]].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(subset_corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title('Heatmap Korelasi untuk Subset Kolom')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7X-D_9B72Hyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi outliers dengan box plot\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.boxplot(data=data[data.columns[:5]], orient='h')\n",
        "plt.title('Visualisasi Outliers Kolom Utama')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UJCtK4x-2IcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi fitur (X) dan target (y) - sesuaikan nama kolom target\n",
        "X = data.drop(columns='col_20')  # Ganti 'col_target' dengan nama kolom target Anda\n",
        "y = data['col_20']               # Ganti 'col_target' dengan nama kolom target Anda\n",
        "\n",
        "# Membagi dataset menjadi training dan testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QLSNbpxD8Ayl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan SelectKBest untuk memilih 10 fitur terbaik berdasarkan korelasi dengan target\n",
        "selector = SelectKBest(score_func=f_regression, k=20)\n",
        "X_train_reduced = selector.fit_transform(X_train, y_train)\n",
        "X_test_reduced = selector.transform(X_test)\n",
        "\n",
        "# Membuat pipeline baru dengan degree yang lebih rendah\n",
        "poly_pipeline_reduced = Pipeline([\n",
        "    ('poly_features', PolynomialFeatures(degree=1)),  # Mulai dengan degree=1\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Melatih model\n",
        "poly_pipeline_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_poly_reduced = poly_pipeline_reduced.predict(X_test_reduced)\n",
        "mse_poly_reduced = mean_squared_error(y_test, y_pred_poly_reduced)\n",
        "print(\"Mean Squared Error (Polynomial Regression with reduced features):\", mse_poly_reduced)"
      ],
      "metadata": {
        "id": "GQB4mAmy8Cee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline untuk Decision Tree Regression\n",
        "tree_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', DecisionTreeRegressor(max_depth=20))  # Ubah max_depth sesuai kebutuhan\n",
        "])\n",
        "\n",
        "# Melatih model\n",
        "tree_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_tree = tree_pipeline.predict(X_test)\n",
        "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
        "print(\"Mean Squared Error (Decision Tree Regression):\", mse_tree)"
      ],
      "metadata": {
        "id": "jbRPBHYu_Rmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline untuk k-Nearest Neighbors Regression\n",
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', KNeighborsRegressor(n_neighbors=5))  # Ubah n_neighbors sesuai kebutuhan\n",
        "])\n",
        "\n",
        "# Melatih model\n",
        "knn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_knn = knn_pipeline.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "print(\"Mean Squared Error (k-NN Regression):\", mse_knn)"
      ],
      "metadata": {
        "id": "p7dU_u7kCynD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline untuk k-Nearest Neighbors Regression\n",
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', KNeighborsRegressor(n_neighbors=5))  # Ubah n_neighbors sesuai kebutuhan\n",
        "])\n",
        "\n",
        "# Melatih model\n",
        "knn_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_knn = knn_pipeline.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "print(\"Mean Squared Error (k-NN Regression):\", mse_knn)"
      ],
      "metadata": {
        "id": "sLaS9HEjECSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline untuk XGBoost Regression\n",
        "xgb_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, objective='reg:squarederror'))\n",
        "])\n",
        "\n",
        "# Melatih model\n",
        "xgb_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "print(\"Mean Squared Error (XGBoost Regression):\", mse_xgb)"
      ],
      "metadata": {
        "id": "19H8NMGDEC11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean Squared Error (Polynomial Regression with reduced features):\", mse_poly_reduced)\n",
        "print(\"Mean Squared Error (Decision Tree Regression):\", mse_tree)\n",
        "print(\"Mean Squared Error (k-NN Regression):\", mse_knn)\n",
        "print(\"Mean Squared Error (XGBoost Regression):\", mse_xgb)"
      ],
      "metadata": {
        "id": "R6O9v8zjHNd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Library\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "\n",
        "# 1. Definisikan Pipeline untuk Decision Tree\n",
        "tree_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Standardisasi data\n",
        "    ('regressor', DecisionTreeRegressor(random_state=42))  # Model Decision Tree\n",
        "])\n",
        "\n",
        "# 2. Parameter Grid untuk RandomizedSearchCV\n",
        "param_grid_tree = {\n",
        "    'regressor__max_depth': [5, 10, 20],         # Kedalaman maksimal pohon\n",
        "    'regressor__min_samples_split': [2, 5, 10], # Minimal sampel untuk split\n",
        "    'regressor__min_samples_leaf': [1, 2, 4]    # Minimal sampel di setiap leaf node\n",
        "}\n",
        "\n",
        "# 3. RandomizedSearchCV untuk Tuning Parameter\n",
        "random_search_tree = RandomizedSearchCV(\n",
        "    tree_pipeline,\n",
        "    param_distributions=param_grid_tree,\n",
        "    n_iter=5,  # Jumlah kombinasi parameter yang diuji\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,      # 3-fold cross-validation\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 4. Melatih RandomizedSearchCV\n",
        "random_search_tree.fit(X_train, y_train)\n",
        "\n",
        "# 5. Evaluasi Model Terbaik\n",
        "best_params_tree = random_search_tree.best_params_\n",
        "y_pred_tree = random_search_tree.best_estimator_.predict(X_test)\n",
        "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
        "\n",
        "print(\"Optimal Parameters:\", best_params_tree)\n",
        "print(\"Mean Squared Error (Best Decision Tree):\", mse_tree)"
      ],
      "metadata": {
        "id": "fece6WSRhq3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Parameter Grid untuk k-NN\n",
        "param_grid_knn = {\n",
        "    'regressor__n_neighbors': [3, 5, 7, 10],\n",
        "    'regressor__weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# GridSearchCV untuk k-NN\n",
        "knn_search = GridSearchCV(\n",
        "    knn_pipeline,\n",
        "    param_grid=param_grid_knn,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "# Melatih GridSearchCV\n",
        "knn_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi Model Terbaik\n",
        "best_params_knn = knn_search.best_params_\n",
        "y_pred_knn = knn_search.best_estimator_.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "\n",
        "print(\"Optimal Parameters (k-NN):\", best_params_knn)\n",
        "print(\"Mean Squared Error (Best k-NN):\", mse_knn)"
      ],
      "metadata": {
        "id": "V_mihFHQ1CGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Grid untuk XGBoost\n",
        "param_grid_xgb = {\n",
        "    'regressor__n_estimators': [50, 100, 200],\n",
        "    'regressor__max_depth': [3, 5, 7],\n",
        "    'regressor__learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV untuk XGBoost\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb_pipeline,\n",
        "    param_distributions=param_grid_xgb,\n",
        "    n_iter=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Melatih RandomizedSearchCV\n",
        "xgb_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi Model Terbaik\n",
        "best_params_xgb = xgb_search.best_params_\n",
        "y_pred_xgb = xgb_search.best_estimator_.predict(X_test)\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "\n",
        "print(\"Optimal Parameters (XGBoost):\", best_params_xgb)\n",
        "print(\"Mean Squared Error (Best XGBoost):\", mse_xgb)"
      ],
      "metadata": {
        "id": "o8FJy5IU1GFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Grid untuk Polynomial Regression\n",
        "param_grid_poly = {\n",
        "    'poly_features__degree': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# GridSearchCV untuk Polynomial Regression\n",
        "poly_search = GridSearchCV(\n",
        "    poly_pipeline_reduced,\n",
        "    param_grid=param_grid_poly,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "# Melatih GridSearchCV\n",
        "poly_search.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Evaluasi Model Terbaik\n",
        "best_params_poly = poly_search.best_params_\n",
        "y_pred_poly = poly_search.best_estimator_.predict(X_test_reduced)\n",
        "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
        "\n",
        "print(\"Optimal Parameters (Polynomial Regression):\", best_params_poly)\n",
        "print(\"Mean Squared Error (Best Polynomial Regression):\", mse_poly)\n"
      ],
      "metadata": {
        "id": "MjvwPHXP1Oyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter Grid untuk Polynomial Regression\n",
        "param_grid_poly = {\n",
        "    'poly_features__degree': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# GridSearchCV untuk Polynomial Regression\n",
        "poly_search = GridSearchCV(\n",
        "    poly_pipeline_reduced,\n",
        "    param_grid=param_grid_poly,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "# Melatih GridSearchCV\n",
        "poly_search.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Evaluasi Model Terbaik\n",
        "best_params_poly = poly_search.best_params_\n",
        "y_pred_poly = poly_search.best_estimator_.predict(X_test_reduced)\n",
        "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
        "\n",
        "print(\"Optimal Parameters (Polynomial Regression):\", best_params_poly)\n",
        "print(\"Mean Squared Error (Best Polynomial Regression):\", mse_poly)\n"
      ],
      "metadata": {
        "id": "zESHiMK71QHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Membuat DataFrame untuk perbandingan\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Decision Tree', 'k-NN', 'XGBoost', 'Polynomial Regression'],\n",
        "    'MSE': [mse_tree, mse_knn, mse_xgb, mse_poly]\n",
        "})\n",
        "\n",
        "# Menambahkan kolom untuk MAE dan RÂ² jika diperlukan\n",
        "comparison_df.sort_values(by='MSE', ascending=True, inplace=True)\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "id": "DtCsmt9q1TnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_test)), y_test, label='Actual', alpha=0.7)\n",
        "plt.scatter(range(len(y_test)), y_pred_xgb, label='Predicted (XGBoost)', alpha=0.7, color='red')\n",
        "plt.title(\"Actual vs Predicted (XGBoost)\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Target Value\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2BYoDo7W1Un0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}