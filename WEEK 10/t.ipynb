{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 2070 SUPER\n",
      "Device digunakan: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup perangkat (CPU/GPU)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device digunakan:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4898, 12)\n",
      "Columns: Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "# 2. Load Dataset\n",
    "data = pd.read_csv('winequality-white.csv', delimiter=';')  # Gunakan ';' sebagai pemisah\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"Columns:\", data.columns)\n",
    "print(data.head())\n",
    "\n",
    "# Validasi dataset\n",
    "if data.shape[1] < 2:\n",
    "    raise ValueError(\"Dataset harus memiliki minimal satu kolom fitur dan satu kolom target!\")\n",
    "\n",
    "# Split fitur dan target\n",
    "X = data.iloc[:, :-1].values  # Semua kolom kecuali terakhir\n",
    "y = data.iloc[:, -1].values   # Kolom terakhir\n",
    "\n",
    "# Handle NaN pada dataset\n",
    "if np.isnan(X).any() or np.isnan(y).any():\n",
    "    print(\"Handling NaN values in the dataset...\")\n",
    "    X = np.nan_to_num(X)\n",
    "    y = np.nan_to_num(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocessing Data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)  # Normalisasi fitur\n",
    "y = (y - y.min()) / (y.max() - y.min())  # Normalisasi target\n",
    "\n",
    "# Split data menjadi train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert ke tensor PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model MLP\n",
    "class MLPRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, activation_function):\n",
    "        super(MLPRegression, self).__init__()\n",
    "        layers = []\n",
    "        for hidden_neurons in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, hidden_neurons))\n",
    "            layers.append(activation_function)\n",
    "            input_dim = hidden_neurons\n",
    "        layers.append(nn.Linear(input_dim, 1))  # Output layer\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Fungsi Pelatihan dan Evaluasi\n",
    "def train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor).squeeze()\n",
    "        if torch.isnan(y_pred).any():\n",
    "            raise ValueError(\"Model predictions contain NaN!\")\n",
    "        mse = mean_squared_error(y_test_tensor.cpu().numpy(), y_pred.cpu().numpy())\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning selesai. Hasil disimpan di results.csv.\n"
     ]
    }
   ],
   "source": [
    "# 6. Hyperparameter Tuning\n",
    "hidden_layers_configs = [\n",
    "    [4], [8], [16], [32], [64],  # 1 hidden layer\n",
    "    [8, 16], [16, 32], [32, 64],  # 2 hidden layers\n",
    "    [8, 16, 32], [16, 32, 64]    # 3 hidden layers\n",
    "]\n",
    "activation_functions = [nn.Identity(), nn.Sigmoid(), nn.ReLU(), nn.Tanh()]  # Hapus Softmax\n",
    "epochs_list = [1, 10, 25, 50, 100, 250]\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001]  # Perbaiki learning rate\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512]\n",
    "\n",
    "results = []\n",
    "\n",
    "for hidden_layers in hidden_layers_configs:\n",
    "    for activation_function in activation_functions:\n",
    "        for epochs in epochs_list:\n",
    "            for lr in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    model = MLPRegression(X_train.shape[1], hidden_layers, activation_function).to(device)\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "                    try:\n",
    "                        mse = train_and_evaluate(model, optimizer, criterion, train_loader, test_loader, epochs)\n",
    "                        results.append((hidden_layers, activation_function.__class__.__name__, epochs, lr, batch_size, mse))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Skipping configuration due to error: {e}\")\n",
    "                        continue\n",
    "\n",
    "# Save Results\n",
    "results_df = pd.DataFrame(results, columns=[\"Hidden Layers\", \"Activation Function\", \"Epochs\", \"Learning Rate\", \"Batch Size\", \"MSE\"])\n",
    "results_df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "print(\"Hyperparameter tuning selesai. Hasil disimpan di results.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
